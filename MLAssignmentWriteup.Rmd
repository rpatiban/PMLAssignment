---
title: "PML - Prediction Assignment Writeup"
author: "Raghu"
date: "October 23, 2015"
output: html_document
---

Human Activity Recognition - qualitative activity recognition
===

###Background

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: [http://groupware.les.inf.puc-rio.br/har](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).


###Goal
The goal of your project is to predict the manner in which they did the exercise. This is the `classe` variable in the training set.



```{r}
setwd("C:/Raghu/Rscipts/ML")

# downloading training set
if(!file.exists("./data")){dir.create("./data")}
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(fileUrl1, destfile = "./data/training.csv", method="curl")
train <- read.csv("./data/training.csv")

dim(train)

table(train$classe)

```

### Data clean up and Train data Split

Removing unnecessary columns and the columns that has NAs.

Train data is further split into 70-30 for training and testing, which helps performing cross validation testing the model fit before we put it for testing on the actual test data.



```{r}
set.seed(32768)

## remove NA columns - # 2 indicates Columns
NACols <- apply(train,2,function(x) {sum(is.na(x))});
noNAsTrain <- train[,which(NACols == 0)];

# Removing unnecessary columns
unNecessaryColumns <- grep("timestamp|X|user_name|new_window",names(noNAsTrain));
cleanedTrain <- noNAsTrain[,-unNecessaryColumns];

library(caret);

# Removing near zero varience columns
# nearZeroVar diagnoses predictors that have one unique value (i.e. are zero variance predictors)
colNZV <- nearZeroVar(cleanedTrain)
cleanedTrain <- cleanedTrain[, -colNZV]

# splitting train into train and test data sets.
inTrain <- createDataPartition(y=cleanedTrain$classe, p=0.70, list=FALSE)
inTrain_training <- cleanedTrain[inTrain,]
inTrain_testing <- cleanedTrain[-inTrain,]
dim(inTrain_training)
dim(inTrain_testing)

# Resampling using cross validation

```

### Model Fit

Because of the characteristic noise in the sensor data, I think, `Random Forest` approach is more appropriate and provides better accuracy. This algorithm is characterized by a subset of features, selected in a random and independent manner with the same distribution for each of the trees in the forest.


```{r}

require(randomForest)
modRF <- randomForest(classe~.,data=inTrain_training,  importance=TRUE, ntrees = 10 )
modRF
#imps <- varImp(fit)
#order(imps)
```


###Confusion Matrix on training dataset
The outcome of confusion matrix on the training dataset should show the high accuracy since `Random Forest` model fit occurred on the same dataset.

```{r}

ptraining <- predict(modRF, inTrain_training)
print(confusionMatrix(ptraining, inTrain_training$classe))
```

Please note the perfect accuracy in the above outcome.

###Cross Validation
Here we are performing the prediction with intrain_testing dataset which is considered as `CV` dataset.  Confusion Matrix should show the high accuracy on this set as well, if above model fit is appropriate. 


```{r}
ptraining <- predict(modRF, inTrain_testing)
print(confusionMatrix(ptraining, inTrain_testing$classe))


```

The cross validation accuracy is 99.7% and the out-of-sample error is therefore 0.3% so our model fit is a highly appropriate.


### Testing with Testset
Now performing predictions on the actual test data.

```{r}

# downloading testing set
if(!file.exists("./data")){dir.create("./data")}
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(fileUrl1, destfile = "./data/testing.csv", method="curl")
test <- read.csv("./data/testing.csv")

dim(test)

```

###Predicting using the model `modRF`

```{r}
testPreds <- predict(modRF, test)
testPreds
table(testPreds)

```

###Writting to files using the given function for submission

```{r}

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

answers <- as.vector(testPreds)
pml_write_files(answers)


```


***After submission, I see that all the 20 predictions turned out to be correct***
